 # Què és BigQuery? 
 
La documentació oficial ho descriu com un magatzem de dades multicloud sense servidor, altament escalable i rendible, dissenyat específicament per a l'agilitat empresarial. 
 
Les paraules clau en aquesta definició són **sense servidor**, cosa que significa que els usuaris poden fer ús de BigQuery sense haver de proporcionar cap servidor pel seu compte.
BigQuery **s'escalarà automàticament** per a gestionar fins a petabytes de dades, per la qual cosa mai haurem de preocupar-nos per la grandària de les dades amb els quals treballem. 
Ser **econòmic** i tenir la capacitat de combinar plataformes en el núvol és també un punt fort.
I BigQuery és essencialment un **magatzem de dades**. Recordem ràpidament llavors què és un magatzem de dades per a posar les coses en context. Es tracta d'un sistema per a l'elaboració d'informes, així com per a l'anàlisi de dades, i els magatzems són coneguts per la seva capacitat per a manejar volums molt grans de dades que han estat compilats a partir de moltes fonts diferents. L'objectiu principal de l'ús d'un magatzem de dades és extreure informació significativa que pugui impulsar les seves decisions de negoci, i BigQuery és més que capaç de complir aquest rol.

## Per què hauríem d'utilitzar BigQuery en lloc d'altres eines?

Bé, per a començar, es tracta d'una plataforma sense servidor. De fet, això significa que els servidors s'executen en segon pla, però l'usuari s'abstreu totalment d'això. I significativament, no han de preocupar-se per la sobrecàrrega de la gestió dels servidors.


BigQuery també té una alta disponibilitat. No cal preocupar-se per la caiguda dels servidors, ja que el servei s'encarrega d'això. Ja hem parlat de l'escalabilitat de BigQuery. Això inclou l'autoescalat de clústers basat en la demanda de dades. I l'escalat és capaç de fer front a petabytes de dades.

Aquestes són característiques que no estan disponibles en la majoria dels magatzems tradicionals. Com en molts altres magatzems, BigQuery és capaç de treballar amb moltes fonts de dades diferents. Pot extreure dades del seu propi sistema d'arxius, de Google Cloud Storage o fins i tot de les galledes S3 de Amazon. A continuació, pot consultar aquestes dades utilitzant SQL estàndard o fins i tot SQL heretat si realment ho necessita. El rendiment en qualsevol cas és excel·lent. Els resultats de les consultes solen emmagatzemar-se en la caixet durant 24 hores, de manera que les següents execucions d'aquesta consulta només hauran d'obtenir les dades de la caixet en lloc de fer-ho del disc. A més, el cost total de propietat de BigQuery és relativament baix en comparació amb moltes de les ofertes equivalents d'altres plataformes en el núvol. Parlant d'això, aquí estan algunes de les alternatives a BigQuery de Google. En Amazon Web Services està Redshift, està SQL Data Warehouse en el núvol Azure, i també està la plataforma Snowflake.


# Arrangement of data in BigQuery


Una vegada vista l'arquitectura de BigQuery, podem passar a alguna cosa que és una mica més tangible per a nosaltres com a usuaris, que és la disposició de les dades.

Per a començar, donem un cop d'ull a les taules, que per descomptat és una estructura de dades on la informació s'organitza en forma de files i columnes. Les taules són una part essencial de BigQuery, i normalment treballaràs amb moltes d'elles. I els permisos es poden assignar fins i tot a nivell de taula individual. Per tant, si bé podem accedir a les dades en les taules, també podem arribar a ells utilitzant vistes, que són en essència derivats de les taules. Com en la majoria de les bases de dades relacionals, les vistes en BigQuery es construeixen mitjançant consultes sobre una o diverses taules subjacents. Quin és llavors el propòsit d'una vista? Bé, el propòsit principal és ocultar la complexitat d'una consulta subjacent. Una vista pot definir-se com una consulta que implica múltiples unions i operacions complexes sobre les dades. I aquesta mateixa operació es pot realitzar amb una simple consulta contra la vista. És important destacar que les vistes en BigQuery no emmagatzemen cap dada per si mateixes. En essència, són capes d'abstracció entre un usuari i les taules subjacents. No obstant això, també és possible assignar permisos a nivell de vista sense concedir als usuaris accés directe a les taules subjacents. Atès que les vistes no emmagatzemen cap dada per si mateixes, el cost d'executar consultes contra les vistes és el mateix que el de consultar les dades subjacents. El que és una mica diferent d'una vista estàndard de BigQuery és una vista materialitzada. Aquesta també es defineix com una consulta contra les dades subjacents. No obstant això, les dades retornades per l'execució de la consulta s'emmagatzemen en caixet. Així que una consulta contra una vista materialitzada és una consulta contra aquestes dades en caixet.


Podem configurar exactament la freqüència amb la qual ha de refrescar-se aquesta caixet per a evitar que els usuaris de les vistes materialitzades rebin dades obsoletes. Alguns dels casos d'ús d'aquesta mena de vistes inclouen la preagregació de dades perquè l'agregació no hagi de realitzar-se sobre la marxa, i puguem simplement recuperar-los tal qual des de la vista materialitzada. De la mateixa manera, es poden utilitzar per a emmagatzemar dades prefiltrados, de manera que només s'emmagatzemi en la vista materialitzada la informació rellevant de les taules subjacents. I de la mateixa manera, podem evitar les operacions d'unió sobre la marxa emmagatzemant les dades d'unió en aquestes vistes.



# Creating and working with datasets and tables

## Configuring the GCP

We now move on to the demos of this course, where we start off by logging into the Google Cloud Platform and then enabling the Compute Engine API in a project, which will set us up to start using BigQuery. To log into Google Cloud, we navigate in our browsers to console.cloud.google.com, at which point we will need to enter our credentials. I'll just type those in. And I assume at this point that you already have a GCP account and have access to credentials which has the necessary permissions to create resources in a GCP project. For me, this is the user cloud.user@loonycorn.com. I'll just enter the password next. And then once we are connected to Google Cloud, make sure that you are connected to a project where you have the ability to create resources. For me, this is one called loony-bigquery, which I have created specifically for this course. If you'd like to switch projects, you can of course click on this. And then once you select the right organization, which for me is loonycorn.com, you can choose among the projects where you have the necessary permissions. Once that is done, let's move along to the next step of making sure that BigQuery is able to create the compute resources that are required in order to store and then also query the data we'll be working with, for which we will enable the Compute Engine API. For this we can pull up the menu for the Google Cloud and then scroll along to the section of APIs & Services. More specifically, we will pull up Enabled for APIs & services. Here, in order for us to turn on the Compute Engine API, let's click on this Enable button, and then we can make use of the search bar in order to search for Compute Engine. Given it is a widely used API, you should be able to scroll along, and at least at the time of this recording, you will find it under the section of Google Cloud APIs. To turn it on for this project, let's just click on it and choose the option to Enable. And with that done, we have now effectively allowed BigQuery to create VMs on our behalf, so that from our point of view, BigQuery is a serverless platform. That is, we are abstracted from the provisioning of servers. And now to make use of BigQuery, we head over to the menu for GCP again, and I'll scroll along to the BigQuery product. Given that this is a service we will be using quite frequently in this course, it will help if we just happen to pin this so that it appears towards the top of the menu. And then from here, let's pull up the SQL workspace of the BigQuery service. This is the interface from which most of the BigQuery operations can be performed. Once we head over to it, we can see precisely what the SQL workspace looks like. There is an Explorer section on the left which allows us to navigate into projects, data sets, and tables. And at this point, a SQL Editor has popped up towards the right where we can define queries on our data.

## Creating a BigQuery dataset

Since we will be using a lot of the SQL workspace interface, let's quickly explore its different features before we move on to creating a data set within our project. From the menu for BigQuery, you'll note that there are separate sections for the data transfer service. We can also set up scheduled queries. And separately, there is an administration section where we can monitor our queries and also configure slot capacities for BigQuery for different teams. All of these are beyond the scope of this course, however, so let's move on. And over to the explorer section, which is very useful when we wish to navigate over to specific data sets or tables. But once we're ready to work with them, we could minimize it to give us more room to work with the query editor and also the results of the query executions, which will come up in the same pane. Let me just bring that back up, and then move on to the features and info section, which will merely point you to a quick start guide for BigQuery and the release notes of the newest versions. If you are someone who likes to use keyboard shortcuts whenever possible, well, pulling up the shortcut menu will point you to the combination of keys which you can use in order to run queries, format them, and so on. Just in case you are wondering about the disable editor tabs button, it is likely that you do not have access to this because tab editors are always on by default from April, 2022. Alright, then it's time for us to create a new data set within a project. Just as a quick reminder, you can think of a dataset in BigQuery as being a logical grouping of tables, and data sets in turn are placed inside projects. The datasets I will be creating in this course will be placed inside this loony-bigquery project. So I'm just going to choose to pin this so that it is easily accessible in this explorer. And then when we expand this project, we should be able to see all of the data sets, which are present inside. And sure enough, there are none in here. To create one, we can just pull up the menu and then choose the option to create a new data set. And then there are various details for the data set, which we can set. We have the option here to change the project where it'll be provisioned. This will pull up a navigator where you can specify the project. I'll just cancel out of this view and head over to the dataset ID. I'm just going to call this one loony_university since we are learning BigQuery at this point. And then there is the data location. This determines where the underlying resources such as compute and storage will be provisioned for the BigQuery service. The considerations when choosing a location will include performance for the end users, high availability, and also any audit or compliance restrictions. Low CO2 emissions may also be a factor in your division. Rather than be tied down to a specific location, there is also the option of multiple regions in the US or in the EU, which may be applicable to your organization. I'll just stick with the United States here. And then we can set a default expiration time for the tables within a data set. I'll enable this and then set the data in the tables to be purged after seven days. This is an option you will use if the work you're about to perform with BigQuery is of a transient nature and you'd like to avoid incurring storage costs beyond the life of your project. You may also set up encryption for the data, but I'll just ignore that option and move on to creating the data set. And you'll note that the loony_university data set now shows up within my project. And expanding this points to the fact that there are no tables within this. Now, if you would like to take a look at the details associated with this data set. From this menu, we can choose to open it up, at which point the dataset information pops up on the right. Here we can confirm the dataset ID, which also points to the project where the dataset has been created, and then other details including the created and modified times. This is the interface we will use if you would like to share the dataset with other users. You'll note that there are also options to copy and delete this data set. And then under edit details, we can reconfigure the expiration time for the tables, set a description, or add labels. For instance, if you would like to mark this particular data set as belonging to a team, we can set a label with a key of team and then a corresponding value. Then when we save down this data set, you'll note that the labels pop up under info. 
=======
Un altre tipus de vista suportada en BigQuery és la vista autoritzada. Als usuaris se'ls pot concedir accés a aquestes vistes, que no és el mateix que concedir-los accés a les dades subjacents. Si una vista autoritzada es crea aplicant alguns filtres a les dades subjacents, un usuari de la vista només podrà veure aquestes dades filtrades i no podrà tenir accés a les taules d'origen. No obstant això, per a habilitar les vistes autoritzades, la pròpia vista ha d'estar autoritzada per a consultar les dades d'origen.

Ara que ja coneixem els diferents tipus de vistes en BigQuery, sabem que es pot accedir a les dades a través de les vistes o consultant les taules. És probable que acabem tenint una sèrie de taules i vistes relacionades, i per a agrupar-les, BigQuery ofereix una construcció anomenada conjunt de dades. Al seu torn, els conjunts de dades poden agrupar-se en un projecte GCP.

BigQuery adopta el model de dades en columnes. Per tant, encara que cada taula s'organitza en files i columnes, és cada columna la que s'emmagatzema per separat en un bloc d'arxius. A diferència de les bases de dades relacionals, en les quals les files o registres s'emmagatzemen junts, BigQuery emmagatzema les dades de les taules com a columnes. Si una consulta sol·licita columnes específiques en la seva taula, són només els blocs d'arxiu corresponents els que es recuperaran i processaran. Això, per descomptat, pot fer que les tasques d'anàlisis de dades o de processament analític en línia siguin molt, molt eficients. Però més enllà d'això, BigQuery també ens permet mutar les dades de les nostres taules, encara que aquestes operacions no seran tan eficients com en una base de dades transaccional. Encara que les dades s'emmagatzemen com a columnes, això no significa que tota la columna s'emmagatzemi junta. Aquestes, al seu torn, poden dividir-se en segments denominats particions. La partició pot basar-se en un dels camps de la seva taula, però aquests han de ser sencers o de tipus temporal. Alternativament, també pot *particionar* les seves dades en funció de l'hora d'ingesta. Un avantatge crucial de la partició és que redueix el nombre de bytes que cal llegir, ja que les dades que es necessiten poden recuperar-se de només un grapat de particions en lloc d'haver de processar tota una columna de dades. A més, el *particionamiento* també millora el rendiment de les consultes, ja que cal escanejar i processar menys dades. I, per a millorar encara més el rendiment, el *particionamiento* pot combinar-se amb l'agrupació de taules, que és una forma més de col·locar les dades relacionades.

# Creating and Working with Datsets and Tables

## Configuring the GCP

Per a iniciar sessió en Google Cloud, naveguem en els nostres navegadors a console.cloud.google.com

Aquesta és la interfície des de la qual es poden realitzar la majoria de les operacions de BigQuery. Una vegada que ens dirigim a ella, podem veure precisament com és l'espai de treball SQL. Hi ha una secció de l'Explorador a l'esquerra que ens permet navegar en projectes, conjunts de dades i taules. I en aquest punt, ha aparegut un Editor SQL cap a la dreta on podem definir consultes sobre les nostres dades.

## Creating a BigQuery dataset

La secció de l'explorador és molt útil quan volem navegar cap a conjunts de dades o taules específiques. Però una vegada que estiguem llestos per a treballar amb ells, podem minimitzar-ho per a tenir més espai per a treballar amb l'editor de consultes i també amb els resultats de les execucions de les consultes, que apareixeran en el mateix panell. 

Molt bé, llavors és el moment de crear un nou conjunt de dades dins d'un projecte. Com a recordatori ràpid, pots pensar en un conjunt de dades en *BigQuery* com una agrupació lògica de taules, i els conjunts de dades al seu torn es col·loquen dins dels projectes. Els conjunts de dades que crearé en aquest curs es col·locaran dins d'aquest projecte *loony-bigquery*, i quan ampliem aquest projecte, podrem veure tots els conjunts de dades que hi ha dins. Per a crear un, només hem de desplegar el menú i després triar l'opció de crear un nou conjunt de dades. I després hi ha diversos detalls per al conjunt de dades, que podem establir. Tenim l'opció de canviar el projecte en el qual serà aprovisionat. Això farà que aparegui un navegador on es pot especificar el projecte. Sortiré d'aquesta vista i em dirigiré al *ID* del conjunt de dades. Cridaré a aquest *loony_university* ja que estem aprenent *BigQuery* en aquest punt. I després està la ubicació de les dades. Això determina on s'aprovisionaran els recursos subjacents, com la computació i l'emmagatzematge, per al servei *BigQuery*. Les consideracions a l'hora de triar una ubicació inclouran el rendiment per als usuaris finals, l'alta disponibilitat i també qualsevol restricció d'auditoria o compliment. Les baixes emissions de CO2 també poden ser un factor en la seva divisió. En lloc d'estar lligat a una ubicació específica, també existeix l'opció de múltiples regions als EUA o a la UE, que pot ser aplicable a la seva organització. I després podem establir un temps d'expiració per defecte per a les taules dins d'un conjunt de dades. Activaré això i després establir les dades en les taules per a ser purgat després de set dies. Aquesta és una opció que utilitzaràs si el treball que realitzaràs amb *BigQuery* és de naturalesa transitòria i vols evitar incórrer en costos d'emmagatzematge més enllà de la vida del teu projecte. També pots configurar l'encriptació de les dades, però ignoraré aquesta opció i passar a crear el conjunt de dades. 

I notaràs que el conjunt de dades *loony_university* ara apareix dins del meu projecte. I ampliant això s'observa que no hi ha taules dins d'això. Ara, si vols donar un cop d'ull als detalls associats a aquest conjunt de dades. Des d'aquest menú, podem triar obrir-lo, moment en el qual la informació del conjunt de dades apareix a la dreta. Aquí podem confirmar l'ANEU del conjunt de dades, que també assenyala el projecte en el qual s'ha creat el conjunt de dades, i després altres detalls que inclouen les hores de creació i modificació. Aquesta és la interfície que utilitzarem si volem compartir el conjunt de dades amb altres usuaris. Veuràs que també hi ha opcions per a copiar i eliminar aquest conjunt de dades. I després, a editar detalls, podem reconfigurar el temps de caducitat de les taules, establir una descripció o afegir etiquetes. Per exemple, si volem marcar aquest conjunt de dades com a pertanyent a un equip, podem establir una etiqueta amb la clau d'equip i el valor corresponent. Després, quan guardem aquest conjunt de dades, notaràs que les etiquetes apareixen en informació.

## Defining a BigQuery table from the UI

Després d'haver creat un conjunt de dades en un projecte *GCP*, és el moment de crear una taula dins del conjunt de dades. Si tenim la informació del conjunt de dades, hauríem de veure aquesta opció per a crear una nova taula des d'aquí. Alternativament, podem dirigir-nos al projecte, després al conjunt de dades i triar l'opció de crear una taula. 

Apareixerà un formulari i tindrem l'opció d'especificar una font per a la nostra taula. Això ens permetrà extreure dades de fonts ja existents, com l'emmagatzematge en el núvol de Google, podríem pujar un arxiu dels nostres propis sistemes d'arxius, i després hi ha un grapat d'altres opcions aquí. 
La primera taula que crearem serà bastant simple. De fet, serà una taula buida. També existeix l'opció d'establir un tipus de taula. Encara que existeix l'opció d'establir una taula, per a emmagatzemar les seves dades fora de *BigQuery*, notaràs que no està disponible per a una taula buida, cosa que significa que les nostres dades seran natives del servei *BigQuery*. A continuació, passem a la secció d'Esquema. Podem especificar l'esquema com a text o podem fer ús d'aquesta interfície per a establir les columnes de la nostra taula, incloent-hi els tipus i altres configuracions. La primera columna que definiré és l'ANEU de l'alumne. Per al tipus, podem triar d'un menú, que inclou tots els tipus amb els quals potser ja estàs familiaritzat. Quant a la manera, aquest determinarà si els valors d'aquesta columna poden ser nuls, és a dir, si són anul·lables o si es requereix un valor. També podem establir que els valors siguin d'un tipus repetit com (indistint). També podem establir una descripció, que és opcional, i amb la primera columna definida, passem a la columna número dos. 
L'altra opció a l'hora d'especificar l'esquema d'una taula és definir-lo en forma de text. Notaràs que el format aquí és molt semblant a *JSON* i podem especificar el nom, tipus, manera, així com altres propietats per a cada camp. La versió de text de l'esquema també pot ser útil si vols guardar-ho en algun sistema de control de versions. 

Seguim endavant, llavors. També podem configurar el *particionamiento* d'una taula, que determinarà com es divideixen les seves dades en l'emmagatzematge. La partició pot fer-se sobre la base del temps d'ingestió o sobre la base d'un camp sencer o de data. També podem especificar com agrupar les nostres dades.

## Querying a simple BigQuery table

Ara que hem creat una gran taula de consulta, podem centrar-nos en treballar amb ella. Per a això, bo, primer, ens desplaçarem cap avall aquí, i donar un cop d'ull al primer esquema de la taula. En algun moment de la seva vida, és possible que necessitis editar l'esquema, la qual cosa pots fer prement aquest botó, i després fent els canvis necessaris. Podries canviar les propietats dels camps existents o podries afegir altres nous. Jo deixo les coses com estan, i surto d'aquesta vista, i després passem als detalls de la taula. I aquí és on podem donar un cop d'ull a alguna informació interessant. Més enllà de la identificació de la taula, també podem comprovar la grandària de la taula, que ens donarà una indicació de la quantitat de dades que es processaran, si anéssim a executar consultes contra ella. La grandària d'emmagatzematge a llarg termini assenyala les dades als quals no s'ha accedit en els últims 90 dies, i després, per descomptat, tenim les hores de creació i modificació juntament amb la ubicació de les dades de la taula, que correspon a la ubicació de l'alimentador de dades que va ser reemplaçat. Des d'aquesta interfície, també podem editar els detalls existents d'aquesta taula. Aquí podem establir un temps de caducitat en cas que vulguem anul·lar el que s'ha establert en el nivell del conjunt de dades. També tenim l'opció d'establir una descripció o afegir etiquetes. 

Això ens donarà un cop d'ull a les dades de la taula, i com és lògic, aquí no hi ha dades. Canviarem això i inserir una nova fila de dades per a això ens dirigim a compondre una nova consulta. Des de la interfície que apareix, podem pegar la consulta que necessitem executar. Comencem amb "*insert into*", seguit de la taula en la qual s'ha de realitzar la inserció. Per a això, utilitzem parèntesi, i dins dels parèntesis, utilitzem la sintaxi, data set *name *dot *able *name, que en el meu cas és, *loony *underscore *university.students*. A continuació, en la línia número dos, podem especificar els noms de les columnes per a les quals s'afegiran valors, així que, com s'ha especificat, cadascuna de les cinc columnes presents en la taula, i després, seguit de la paraula clau *values*, especifiquem entre parèntesi, els propis valors. Observi's que en les consultes grans, podem utilitzar cometes dobles en especificar cadenes. També hi ha una altra informació interessant aquí per a la que minimitzaré el panell de l'explorador. Notaràs que hi ha un missatge que assenyala que es processaran zero bytes, quan executem aquesta consulta. Ara, seguirem endavant i executar aquesta consulta, i sembla que la inserció va ser un èxit, atès que una fila s'ha afegit a la taula dels estudiants. Per a confirmar-ho, executem una consulta més, concretament, un *select* from *loony university.students*. Significativament, obtenim un missatge que diu que, en executar aquesta consulta, es processaran 60 bytes de dades, assenyalant el cost que es produirà. Efectivament, l'única fila ha estat retornada, i fins i tot en els resultats de la consulta, obtenim la confirmació que s'han processat 60 bytes. El temps d'execució de la consulta també apareix aquí.

## Uploading data to create a BigQuery table

Mentre que anteriorment vam veure com podem crear una taula buida i després emplenar-la amb dades amb sentències *INSERT*, ara explorarem un cas d'ús més comú per als usuaris de *BigQuery* en el qual es crea una taula a partir de dades existents. Per a això, ens dirigirem al conjunt de dades *loony_university* i triarem crear una nova taula. I aquesta vegada, la font no serà una taula buida, sinó que carregarem un arxiu *CSV* del nostre propi sistema d'arxius per al qual es pot seleccionar l'opció de càrrega. Hi ha algunes restriccions quant a la grandària de l'arxiu que podem pujar. Per tant, aquest ha de romandre dins dels 100 MB. No obstant això, per als arxius més grans, encara podem portar-los a *BigQuery*, sempre que els moguem en l'emmagatzematge en el núvol de Google primer. Procedim llavors a navegar pels nostres sistemes d'arxius per a l'arxiu a pujar. I després navegar fins a *movies_info.csv*. Aquest arxiu està inclòs en els materials del curs. També es pot descarregar des d'aquesta ubicació. Una vegada que l'arxiu ha estat seleccionat. I després obert. Sabrà que el format de l'arxiu s'ha establert automàticament en *CSV*. Perquè et facis una idea, alguns dels altres formats suportats aquí inclouen *JSON* així com *Avro*. Quant al projecte i al conjunt de dades, els deixarem com estan. I després, el nom de la taula, *movies_info*, transmetrà que sí que inclou informació sobre diverses pel·lícules. A continuació, tenim l'opció de definir explícitament l'esquema. No obstant això, atès que es tracta d'un arxiu *CSV* amb múltiples columnes, podem triar l'opció Acte detectar. Aquí, *BigQuery* donarà un cop d'ull al contingut de cada columna i determinarà quin ha de ser l'esquema. Més enllà d'això, deixem tota la resta sense tocar. I després, tria crear la taula. En uns moments, notaràs que *movies_*info apareix sota el conjunt de dades *loony_university*. En cas que no ho vegis, és possible que hagis d'actualitzar la pàgina en el teu navegador. A continuació, podem accedir a la informació de la taula i al seu contingut desplegant el menú i triant Obrir. En l'esquema de la taula, sabrà que s'ha detectat automàticament el tipus dels diferents camps. El nom de la productora, el país en el qual es troba, així com els noms dels directors s'especifiquen com a cadenes, però el pressupost s'ha detectat i establert com un nombre enter. Si continuem avançant, observarem que la columna de puntuació s'ha configurat com un valor de coma flotant. I tenim un grapat d'uns altres en enters i cadenes en l'esquema. Donem un cop d'ull als detalls de la taula. Aquí notaràs que la grandària total és de poc més de 720 *KB*. El nombre de files és d'unes 4.600. I després, quan ens dirigim a la Vista Prèvia, bo, aquí és on obtenim un cop d'ull als continguts. Efectivament, la columna del pressupost és un nombre enter bastant gran. Igual que el tipus d'aquesta columna, el conjunt de dades inclou el nom de l'empresa o de l'estudi que ha produït la pel·lícula. També tenim aquí la informació del director. El gènere de la pel·lícula. I després, desplaçant-se al llarg, el nom o títol de la pel·lícula, juntament amb els diners que va tancar en la taquilla. I després, podem desplaçar-nos més a baix per a donar un cop d'ull a les pel·lícules que són presents en aquest conjunt de dades.

## Querying data and viewing statistics of queries

Ara, per a executar consultes contra aquesta taula *movies_info*, ens dirigim al botó de consulta. Això ens permetrà obrir una nova pestanya de consulta. Aquesta pot ser una pestanya completament nova que ocultarà aquesta vista de detalls, mentre que una pestanya dividida ens permetrà fer referència a aquesta vista de detalls per a la taula mentre construïm una consulta. Observarà que no s'esmenta cap error de sintaxi. I sobre la base d'aquesta selecció, es processarà un total de 94 kilobytes. Si tornem a la vista de l'esquema, podem incloure la columna de pressupost en la clàusula *SELECT*. De nou, s'ha emplenat automàticament. 

Executarem aquesta consulta prement Executar. Els resultats han aparegut, i aquesta consulta s'ha executat en uns 3 segons per a mi. Per descomptat, podem desplaçar-nos i donar un cop d'ull a tots els resultats. No obstant això, el més interessant si ets nou en *BigQuery* són els detalls addicionals en el panell inferior. En concret, si ens dirigim a la secció d'Historial Personal, podem donar un cop d'ull als diferents treballs que s'han creat per a cada operació que hem realitzat. Per exemple, cada treball es classifica com *QUERY* si es realitza un *SELECT* o fins i tot un *INSERT*. Després es pot registrar una operació LLOEU per a quan carreguem les dades de l'arxiu *CSV*. Aquesta interfície sí que ens permet accedir a informació addicional per a cadascun dels treballs. Per exemple, si es mostren els detalls de l'últim treball creat, podem veure el que *BigQuery* ha fet per nosaltres per a assegurar-se que aquesta consulta s'executi i retorni els resultats. Aquí podem veure l'usuari que va iniciar aquest treball, quan es va crear exactament el treball, quan va començar i va acabar, i el més important, el nombre de bytes processats i el nombre de bytes facturats. 

Sortint d'aquesta vista, passem a l'Historial del Projecte, que ens donarà els detalls dels treballs de tot el projecte i no sols del nostre propi usuari. I després està la secció de Consultes Guardades. Aquí és on es pot accedir a les consultes que hàgim guardat, encara que aquestes apareixeran en el menú de l'Explorador al costat dels nostres projectes i conjunts de dades.

## Creating a table from a query result

Després d'haver introduït dades de fonts externes en *BigQuery*. Ara veurem com podem crear noves taules a partir de les existents. L'objectiu és crear una nova taula a partir dels resultats d'aquesta consulta en particular. Aquí apliquem un filtre, no sols eliminant rols a causa de la clàusula *where* i seleccionant només camps específics. Però notaràs en línia número dos que també creguem una nova columna anomenada benefici, que es computa calculant la diferència entre el creixement de les pel·lícules. És a dir, la quantitat de diners que va ingressar i després restant el pressupost d'aquesta. Per descomptat, per a veure el cost associat a aquesta consulta. Podem minimitzar l'Explorador. Quan executem això, els resultats apareixen i hi ha un total de 315 files de dades. Ara hem d'exportar totes aquestes dades a una nova taula. Revisa algunes de les opcions d'exportació. Podem donar un cop d'ull al menú Guardar resultats. Vostè observarà que hi ha un nombre de diferents opcions aquí per a la manera de guardar els resultats. Podem guardar-los com un arxiu *CSV* en Google *Drive* o en un arxiu local. El format *JSON* també està disponible com una opció d'exportació. No obstant això, el que oferirem aquí és exportar el contingut a una nova taula de *BigQuery*. Una vegada feta aquesta selecció, podem decidir el nom del projecte i el conjunt de dades on s'aprovisionarà la taula i després establir un nom de taula. Llavors, quan guardem les coses, això haurà iniciat un nou treball per a aprovisionar la nova taula i carregar-la amb dades. Una vegada que tanquem aquesta notificació, podem treure el pin de l'Explorador i baix *loony_university*, *big_budget_movies* apareix com una taula. En obrir-la confirmem que l'esquema apunta a les mateixes columnes que havíem referenciat en la clàusula *select de la consulta que va crear aquesta taula, encara que hi ha una columna anomenada *profit* el tipus de la qual s'ha establert com un enter. Des dels detalls podem confirmar que el nombre de files coincideix amb el dels resultats de la consulta, concretament 315. I després la vista prèvia ens mostrarà quins són exactament les dades. Desplacem-nos i confirmem que la columna de beneficis es deriva, efectivament, del creixement i del pressupost. 

Quin és llavors la finalitat d'aquesta taula? Bé, atès que només conté un subconjunt de la taula *movie_info* original. Significa que les consultes contra això tindran potencialment menys dades per a processar que les consultes que s'executen directament contra *movies_info*. Si només desitja analitzar. Per a executar una consulta d'aquest tipus, traurem l'Editor de Consultes i a substituir aquesta consulta per aquesta altra, que es dirigeix a una taula recentment creada. Observarà que els camps de la clàusula *select* són idèntics als quals teníem anteriorment, però la clàusula *where* és una mica diferent. I mentre que la consulta anterior va processar 492 kilobytes, aquesta només funcionarà amb 34,7. Seguim endavant i executem aquesta consulta. I els resultats confirmen que les consultes contra aquesta taula funcionen com s'espera que ho facin.

## Creating a query from a filter

Ara cobrirem un mètode més per a crear una taula *BigQuery* a partir del contingut de taules existents. Observarà que en l'editor de consultes entre les línies tres i set tenim una consulta *SELECT contra la taula *movies_info*. La clàusula *WHERE* indica que només ens interessen les pel·lícules en les quals el pressupost ha superat la recaptació. Això significa que la pel·lícula va tenir pèrdues, per la qual cosa en la clàusula *SELECT* tenim el pressupost menys el brut projectat com a columna de pèrdues. Encara que podríem executar la consulta i després utilitzar el menú de guardar resultats per a crear una nova taula a partir dels resultats, una opció potencialment més fàcil, és que incloguem aquestes dues línies en la part superior on creguem una nova taula amb una sentència *CREATE TABLE*. A *CREATE TABLE* li segueix el conjunt de dades i el nom de la taula, que és *lossmaking_movies*. A continuació, utilitzem la paraula clau AS seguida d'una consulta *SELECT* en la qual es retornen resultats dels quals es crearà una nova taula. Quan s'executi aquesta consulta, en uns instants, se'ns notificarà que s'ha creat una nova taula anomenada *lossmaking_movies* en el conjunt de dades *loony_university*. Trauré l'explorador per a accedir a ella. Efectivament, *lossmaking_movies* apareix ara aquí. En obrir-ho, podem donar un cop d'ull a l'esquema de la taula. Observi's que només inclou les columnes seleccionades, que han retallat les dades de la taula *movies_info* original. Després està, per descomptat, la columna de pèrdues. Si només desitgem analitzar les pel·lícules amb pèrdues i evitar haver de calcular-les cada vegada, aquesta taula ens convé perfectament. Els detalls apunten al fet que hi ha més de 2300 pel·lícules en aquesta taula en particular. I finalment, podem *previsualizar* les dades per a confirmar que el pressupost en cada cas supera l'import brut i que la pèrdua es computa correctament. Arribats a aquest punt, no dubti a consultar aquesta taula *lossmaking_movies* per a realitzar una anàlisi més eficient i rendible de les pel·lícules que han sofert pèrdues. Tingui en compte també que podem crear una nova taula unint les dades de dues o més taules existents.

# Executing queries and Visualising results

## Public datasets in BigQuery



## Configuring and using BigQuery caches

## External BigQuery tables

## Integrating BigQuery with Data Studio

# Creating and Working with Views

## Saving query results using views

## Querying views vs querying the original tables

## Materialized views in BigQuery

## Defining a restricted view of data

## Granting a user-level access

## Setting up an authorised view

>>>>>>> 9800ebcf8a60e4e63ef35429f0ca8dbe8bedbb0b
