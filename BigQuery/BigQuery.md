 # Què és BigQuery? 
 
La documentació oficial ho descriu com un magatzem de dades multicloud sense servidor, altament escalable i rendible, dissenyat específicament per a l'agilitat empresarial. 
 
Les paraules clau en aquesta definició són **sense servidor**, cosa que significa que els usuaris poden fer ús de BigQuery sense haver de proporcionar cap servidor pel seu compte.
BigQuery **s'escalarà automàticament** per a gestionar fins a petabytes de dades, per la qual cosa mai haurem de preocupar-nos per la grandària de les dades amb els quals treballem. 
Ser **econòmic** i tenir la capacitat de combinar plataformes en el núvol és també un punt fort.
I BigQuery és essencialment un **magatzem de dades**. Recordem ràpidament llavors què és un magatzem de dades per a posar les coses en context. Es tracta d'un sistema per a l'elaboració d'informes, així com per a l'anàlisi de dades, i els magatzems són coneguts per la seva capacitat per a manejar volums molt grans de dades que han estat compilats a partir de moltes fonts diferents. L'objectiu principal de l'ús d'un magatzem de dades és extreure informació significativa que pugui impulsar les seves decisions de negoci, i BigQuery és més que capaç de complir aquest rol.

## Per què hauríem d'utilitzar BigQuery en lloc d'altres eines?

Bé, per a començar, es tracta d'una plataforma sense servidor. De fet, això significa que els servidors s'executen en segon pla, però l'usuari s'abstreu totalment d'això. I significativament, no han de preocupar-se per la sobrecàrrega de la gestió dels servidors.


BigQuery també té una alta disponibilitat. No cal preocupar-se per la caiguda dels servidors, ja que el servei s'encarrega d'això. Ja hem parlat de l'escalabilitat de BigQuery. Això inclou l'autoescalat de clústers basat en la demanda de dades. I l'escalat és capaç de fer front a petabytes de dades.

Aquestes són característiques que no estan disponibles en la majoria dels magatzems tradicionals. Com en molts altres magatzems, BigQuery és capaç de treballar amb moltes fonts de dades diferents. Pot extreure dades del seu propi sistema d'arxius, de Google Cloud Storage o fins i tot de les galledes S3 de Amazon. A continuació, pot consultar aquestes dades utilitzant SQL estàndard o fins i tot SQL heretat si realment ho necessita. El rendiment en qualsevol cas és excel·lent. Els resultats de les consultes solen emmagatzemar-se en la caixet durant 24 hores, de manera que les següents execucions d'aquesta consulta només hauran d'obtenir les dades de la caixet en lloc de fer-ho del disc. A més, el cost total de propietat de BigQuery és relativament baix en comparació amb moltes de les ofertes equivalents d'altres plataformes en el núvol. Parlant d'això, aquí estan algunes de les alternatives a BigQuery de Google. En Amazon Web Services està Redshift, està SQL Data Warehouse en el núvol Azure, i també està la plataforma Snowflake.


# Arrangement of data in BigQuery


Una vegada vista l'arquitectura de BigQuery, podem passar a alguna cosa que és una mica més tangible per a nosaltres com a usuaris, que és la disposició de les dades.

Per a començar, donem un cop d'ull a les taules, que per descomptat és una estructura de dades on la informació s'organitza en forma de files i columnes. Les taules són una part essencial de BigQuery, i normalment treballaràs amb moltes d'elles. I els permisos es poden assignar fins i tot a nivell de taula individual. Per tant, si bé podem accedir a les dades en les taules, també podem arribar a ells utilitzant vistes, que són en essència derivats de les taules. Com en la majoria de les bases de dades relacionals, les vistes en BigQuery es construeixen mitjançant consultes sobre una o diverses taules subjacents. Quin és llavors el propòsit d'una vista? Bé, el propòsit principal és ocultar la complexitat d'una consulta subjacent. Una vista pot definir-se com una consulta que implica múltiples unions i operacions complexes sobre les dades. I aquesta mateixa operació es pot realitzar amb una simple consulta contra la vista. És important destacar que les vistes en BigQuery no emmagatzemen cap dada per si mateixes. En essència, són capes d'abstracció entre un usuari i les taules subjacents. No obstant això, també és possible assignar permisos a nivell de vista sense concedir als usuaris accés directe a les taules subjacents. Atès que les vistes no emmagatzemen cap dada per si mateixes, el cost d'executar consultes contra les vistes és el mateix que el de consultar les dades subjacents. El que és una mica diferent d'una vista estàndard de BigQuery és una vista materialitzada. Aquesta també es defineix com una consulta contra les dades subjacents. No obstant això, les dades retornades per l'execució de la consulta s'emmagatzemen en caixet. Així que una consulta contra una vista materialitzada és una consulta contra aquestes dades en caixet.


Podem configurar exactament la freqüència amb la qual ha de refrescar-se aquesta caixet per a evitar que els usuaris de les vistes materialitzades rebin dades obsoletes. Alguns dels casos d'ús d'aquesta mena de vistes inclouen la preagregació de dades perquè l'agregació no hagi de realitzar-se sobre la marxa, i puguem simplement recuperar-los tal qual des de la vista materialitzada. De la mateixa manera, es poden utilitzar per a emmagatzemar dades prefiltrados, de manera que només s'emmagatzemi en la vista materialitzada la informació rellevant de les taules subjacents. I de la mateixa manera, podem evitar les operacions d'unió sobre la marxa emmagatzemant les dades d'unió en aquestes vistes.

Some of the use cases of such views include pre-aggregating data so that the aggregation need not be performed on the fly, and we can simply retrieve them as is from the materialized view. Similarly, these can be used to store pre-filtered data, so that only relevant information from the underlying tables is stored in the materialized view. And similarly, we can avoid join operations on the fly by storing the join data in such views. One more type of view supported in BigQuery is the authorized view. Users can be granted access to these views, and significantly, this is not the same as granting them access to the underlying data. If an authorized view is created by applying some filters on underlying data, a user of the view will only be able to view this filtered data and may not have access to the source tables. To enable authorized views, however, the view itself needs to be authorized to query the source data. So now that we have an understanding of the different types of views in BigQuery, we know that data can be accessed either via views or by querying tables. It is likely that you will end up with a number of related tables and views, and to group these together, BigQuery offers a construct called a dataset. Datasets in turn can be grouped together into a GCP project. With that, we have an understanding of how data can be grouped when it comes to BigQuery. But now let's zoom in a little bit on individual tables and see how this is represented. BigQuery adopts the columnar data model. So while each table is arranged as rows and columns, it is each column which is separately stored in a file block. Unlike relational databases where it is rows or records that are stored together, BigQuery stores the data in tables as columns. If a query requests specific columns in your table, it is just the corresponding file blocks which will be retrieved and processed. This of course can make data analysis or online analytical processing tasks very, very efficient. Beyond this, though, BigQuery also allows us to mutate the data in our tables, though these operations won't be as efficient as on a transactional database. While data is stored as columns, this does not mean that the entire column is stored together. These in turn can be split into segments called partitions. The partitioning may be based on one of the fields in your table, but these need to be either an integer or of a temporal type. Alternatively, you may also partition your data based on the time of ingestion. A crucial benefit of partitioning is that it reduces the number of bytes which you need to read, since the data which you need may be retrieved from just a handful of partitions rather than having to process an entire column of data. And we will soon see that this has an effect on the costs of using BigQuery. Furthermore, partitioning also improves query performance since less data needs to be scanned and processed. And, to improve performance even further, partitioning can be combined with table clustering, which is one more means of colocating related data.

#Creating and working with datasets and tables

## Configuring the GCP

We now move on to the demos of this course, where we start off by logging into the Google Cloud Platform and then enabling the Compute Engine API in a project, which will set us up to start using BigQuery. To log into Google Cloud, we navigate in our browsers to console.cloud.google.com, at which point we will need to enter our credentials. I'll just type those in. And I assume at this point that you already have a GCP account and have access to credentials which has the necessary permissions to create resources in a GCP project. For me, this is the user cloud.user@loonycorn.com. I'll just enter the password next. And then once we are connected to Google Cloud, make sure that you are connected to a project where you have the ability to create resources. For me, this is one called loony-bigquery, which I have created specifically for this course. If you'd like to switch projects, you can of course click on this. And then once you select the right organization, which for me is loonycorn.com, you can choose among the projects where you have the necessary permissions. Once that is done, let's move along to the next step of making sure that BigQuery is able to create the compute resources that are required in order to store and then also query the data we'll be working with, for which we will enable the Compute Engine API. For this we can pull up the menu for the Google Cloud and then scroll along to the section of APIs & Services. More specifically, we will pull up Enabled for APIs & services. Here, in order for us to turn on the Compute Engine API, let's click on this Enable button, and then we can make use of the search bar in order to search for Compute Engine. Given it is a widely used API, you should be able to scroll along, and at least at the time of this recording, you will find it under the section of Google Cloud APIs. To turn it on for this project, let's just click on it and choose the option to Enable. And with that done, we have now effectively allowed BigQuery to create VMs on our behalf, so that from our point of view, BigQuery is a serverless platform. That is, we are abstracted from the provisioning of servers. And now to make use of BigQuery, we head over to the menu for GCP again, and I'll scroll along to the BigQuery product. Given that this is a service we will be using quite frequently in this course, it will help if we just happen to pin this so that it appears towards the top of the menu. And then from here, let's pull up the SQL workspace of the BigQuery service. This is the interface from which most of the BigQuery operations can be performed. Once we head over to it, we can see precisely what the SQL workspace looks like. There is an Explorer section on the left which allows us to navigate into projects, data sets, and tables. And at this point, a SQL Editor has popped up towards the right where we can define queries on our data.

## Creating a BigQuery dataset

Since we will be using a lot of the SQL workspace interface, let's quickly explore its different features before we move on to creating a data set within our project. From the menu for BigQuery, you'll note that there are separate sections for the data transfer service. We can also set up scheduled queries. And separately, there is an administration section where we can monitor our queries and also configure slot capacities for BigQuery for different teams. All of these are beyond the scope of this course, however, so let's move on. And over to the explorer section, which is very useful when we wish to navigate over to specific data sets or tables. But once we're ready to work with them, we could minimize it to give us more room to work with the query editor and also the results of the query executions, which will come up in the same pane. Let me just bring that back up, and then move on to the features and info section, which will merely point you to a quick start guide for BigQuery and the release notes of the newest versions. If you are someone who likes to use keyboard shortcuts whenever possible, well, pulling up the shortcut menu will point you to the combination of keys which you can use in order to run queries, format them, and so on. Just in case you are wondering about the disable editor tabs button, it is likely that you do not have access to this because tab editors are always on by default from April, 2022. Alright, then it's time for us to create a new data set within a project. Just as a quick reminder, you can think of a dataset in BigQuery as being a logical grouping of tables, and data sets in turn are placed inside projects. The datasets I will be creating in this course will be placed inside this loony-bigquery project. So I'm just going to choose to pin this so that it is easily accessible in this explorer. And then when we expand this project, we should be able to see all of the data sets, which are present inside. And sure enough, there are none in here. To create one, we can just pull up the menu and then choose the option to create a new data set. And then there are various details for the data set, which we can set. We have the option here to change the project where it'll be provisioned. This will pull up a navigator where you can specify the project. I'll just cancel out of this view and head over to the dataset ID. I'm just going to call this one loony_university since we are learning BigQuery at this point. And then there is the data location. This determines where the underlying resources such as compute and storage will be provisioned for the BigQuery service. The considerations when choosing a location will include performance for the end users, high availability, and also any audit or compliance restrictions. Low CO2 emissions may also be a factor in your division. Rather than be tied down to a specific location, there is also the option of multiple regions in the US or in the EU, which may be applicable to your organization. I'll just stick with the United States here. And then we can set a default expiration time for the tables within a data set. I'll enable this and then set the data in the tables to be purged after seven days. This is an option you will use if the work you're about to perform with BigQuery is of a transient nature and you'd like to avoid incurring storage costs beyond the life of your project. You may also set up encryption for the data, but I'll just ignore that option and move on to creating the data set. And you'll note that the loony_university data set now shows up within my project. And expanding this points to the fact that there are no tables within this. Now, if you would like to take a look at the details associated with this data set. From this menu, we can choose to open it up, at which point the dataset information pops up on the right. Here we can confirm the dataset ID, which also points to the project where the dataset has been created, and then other details including the created and modified times. This is the interface we will use if you would like to share the dataset with other users. You'll note that there are also options to copy and delete this data set. And then under edit details, we can reconfigure the expiration time for the tables, set a description, or add labels. For instance, if you would like to mark this particular data set as belonging to a team, we can set a label with a key of team and then a corresponding value. Then when we save down this data set, you'll note that the labels pop up under info. 